# ğŸ“Š Analysis Index - Resonance Bay Navigator

**Version:** 1.0.0
**Datum:** 6. November 2025
**Verzeichnis:** `analysis/`

---

## ğŸ¯ Was ist das?

Willkommen in der **Analysis Resonance Bay** - dem HerzstÃ¼ck der empirischen UTAC-Validierung! Hier werden logistische Fits Ïƒ(Î²(R-Î˜)) an reale Daten aus 6 DomÃ¤nen gerechnet.

**Trilayer-Navigation:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YAML  â†’  Struktur (32 Python-Skripte)  â”‚  analysis_index.yaml
â”‚  JSON  â†’  Agentenschnittstelle          â”‚  analysis_index.json
â”‚  MD    â†’  Menschenfreundlich (du!)      â”‚  analysis_index.md
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§­ Schnelleinstieg

### ğŸ“ Ordnerstruktur auf einen Blick:

```
analysis/
â”œâ”€â”€ 32 Python-Skripte (Domain-Fits, Batch-Processing, Labs)
â”œâ”€â”€ batch_configs/   (4 YAML/JSON Konfigurationen)
â”œâ”€â”€ batch_runs/      (2 gespeicherte Batch-Runs)
â”œâ”€â”€ reports/         (1 QPO-Summary)
â”œâ”€â”€ sigillin_sync/   (Telemetry-Exports aus `scripts/sigillin_sync.py`)
â””â”€â”€ results/         â­ ZENTRAL! Alle Fit-Ergebnisse (JSON)
```

### ğŸ”¥ Die wichtigsten Dateien:

#### **FÃ¼r UTAC v1.2 kritisch:**
- `beta_drivers_meta_regression.py` - **DER** Kern! Basislinie RÂ²=0.33 â†’ VergleichsmaÃŸstab
- `beta_meta_regression_v2.py` - Bootstrap-Refresh: WLS RÂ²â‰ˆ0.43, Median-Bootstrap RÂ²â‰ˆ0.99 [0.43,1.00], Î”AIC-Minimum 12.79
- `universal_beta_extractor.py` - Canonical Î²-Guard (Î”AICâ‰¥10, RÂ²â‰¥0.9)
- `universality_test.py` - Testet Î²-UniversalitÃ¤t
- `resonance_cohort_summary.py` - Median RÂ²â‰ˆ0.9981, Î”AICâ‰ˆ65.1
- `multiple_testing_correction.py` - Statistische ValiditÃ¤t
- `outlier_beta_review.py` - Instrumentation-Flag Ledger fÃ¼r Amazon & Urban Heat

#### **High-Impact Fits:**
- `llm_beta_extractor.py` - Wei's PaLM (Î²=3.47Â±0.47)
- `lenski_citplus_fit.py` - Evolution (Î²=5.08, Î”AIC>32)
- `seismic_rupture_threshold_fit.py` - Cascadia (Î²=16.29!)
- `urban_heat_canopy_fit.py` - **Î²=16.3 OUTLIER!** ğŸ”¥
- `amazon_resilience_fit.py` - Amazon (Î²=14.6)

#### **Batch-Infrastruktur:**
- `resonance_batch_runner.py` - Batch-Processing
- `resonance_bridge_table.py` - Cross-Referenz-Tabelle
- `resonance_fit_pipeline.py` - Haupt-Pipeline
- `beta_meta_regression_v2.py` - Nichtlineare Meta-Regression + Bootstrap/Random-Forest-Diagnostics

---

## ğŸ“‚ Die 5 Kategorien

### ğŸ”µ Domain-Spezifische Fit-Skripte (16)

**Was?** Python-Skripte fÃ¼r logistische Fits spezifischer DomÃ¤nen

**DomÃ¤nen:**
- **AI (3):** llm_beta_extractor, llm_emergent_skill, introspection_validation
- **Biology (3):** lenski_citplus, synaptic_release, honeybee_waggle
- **Cognition (2):** working_memory_gate, adaptive_theta_plasticity
- **Geophysics (1):** seismic_rupture_threshold (Cascadia)
- **Socio-Ecology (4):** amazon_resilience, urban_heat_canopy, planetary_tipping, outlier_beta_review
- **Cross-Domain (6):** coupled_field, membrane_robin_semantic, meta_threshold, etc.

**Output:** Alle exportieren nach `results/*.json`

---

### ğŸŸ¢ Batch Processing & Pipelines (8)

**Was?** Automatisierung, Cohort-Summaries, Meta-Analysen

**Die Big 8:**
1. `resonance_batch_runner.py` - FÃ¼hrt Batch-Runs aus
2. `resonance_fit_pipeline.py` - Koordiniert Workflow
3. `resonance_cohort_summary.py` - Statistik Ã¼ber alle Results
4. `resonance_bridge_table.py` - Cross-Referenz-Tabelle
5. `universality_test.py` - Î²-UniversalitÃ¤tstest
6. `beta_drivers_meta_regression.py` - **Baseline-Meta-Regression fÃ¼r v1.2 (RÂ²=0.33)**
7. `beta_meta_regression_v2.py` - **Bootstrap & RF Refresh (WLS RÂ²â‰ˆ0.43, Median-Bootstrapâ‰ˆ0.99)**
8. `universal_beta_extractor.py` - Î”AICâ‰¥10 Guard + Canonical Î²

---

### ğŸŸ  Lab Notebooks & Experimentelles (2)

**Was?** Jupyter Notebooks, interaktive Exploration

1. `dynamic_threshold_lab.ipynb` - Jupyter Lab fÃ¼r Threshold-Experimente
2. `potential_cascade_lab.py` - Labor fÃ¼r Potential-Kaskaden

---

### ğŸŸ£ Utilities & Guards (4)

**Was?** Helper-Funktionen, Validierung, Diagnostics

1. `multiple_testing_correction.py` - **Wichtig!** Bonferroni, FDR
2. `preset_alignment_guard.py` - Validiert Preset-Konsistenz
3. `resonant_impedance_diagnostics.py` - Î¶(R) Diagnostics
4. `outlier_beta_review.py` - Î”AIC Outlier-Wacht (instrumentation_flag)

---

### ğŸ”´ Unterverzeichnisse (4)

#### **batch_configs/** - Konfigurationen
- `potential_cascade.yaml`
- `potential_cascade_climate.yaml`
- `potential_cascade_llm.yaml`
- `resonance_runs.json`

#### **batch_runs/** - Gespeicherte Runs
- `honeybee_refresh.json`
- `robin_semantic_demo.json`

#### **reports/** - Summaries
- `qpo_membrane_summary.json` (Astrophysik)

#### **sigillin_sync/** - Telemetry Harness Reports
- `latest.json` â€“ Metaquest sigillin_sync Statusbericht (JSON)

#### **results/** â­ **ZENTRAL!**
**DER wichtigste Ordner!**
- EnthÃ¤lt alle JSON-Exports der Fit-Skripte
- Format: `{domain}_{system}_fit.json`
- Struktur: `{R, Î˜, Î², Î¶(R), Î”AIC, RÂ², CI, ...}`
- Basis fÃ¼r Cohort-Summary, Bridge-Table, Meta-Regression

---

## ğŸ”¬ Die 6 DomÃ¤nen im Detail

### ğŸ¤– AI (3 Skripte)
**Highlights:**
- `llm_beta_extractor.py` - Wei's PaLM-Sweeps, Î²=3.47Â±0.47, Î˜â‰ˆ9.92
- `llm_emergent_skill_fit.py` - Multilingual CoT, Î”AICâ‰ˆ48.8
- `introspection_validation.py` - Anthropic Ï†-Kopplung

**Ergebnisse:** LLMs zeigen klare Threshold-ÃœbergÃ¤nge bei emergenten FÃ¤higkeiten

---

### ğŸ§¬ Biology (3 Skripte)
**Highlights:**
- `lenski_citplus_fit.py` - **LTEE Cit+ Evolution!** Î²=5.08, RÂ²=0.990
- `synaptic_release_fit.py` - Hippocampus Vesicle-Release, Î˜=12.68 Hz
- `honeybee_waggle_fit.py` - Quorum-Call Threshold

**Ergebnisse:** Evolution und neuronale Prozesse folgen logistischen Schwellenwerten

---

### ğŸ§  Cognition (2 Skripte)
**Highlights:**
- `working_memory_gate_fit.py` - Prefrontal Gate, Î²=12.28, RÂ²=0.9986
- `adaptive_theta_plasticity_fit.py` - Sleep-Pressure, Î²=10.86

**Ergebnisse:** Kognitive Prozesse haben scharfe Threshold-ÃœbergÃ¤nge

---

### ğŸŒ Geophysics (1 Skript)
**Highlights:**
- `seismic_rupture_threshold_fit.py` - Cascadia Slow-Slip, Î²=16.29, RÂ²=0.99997!

**Ergebnisse:** Seismische Prozesse zeigen extrem steile ÃœbergÃ¤nge

---

### ğŸŒ¿ Socio-Ecology (4 Skripte)
**Highlights:**
- `amazon_resilience_fit.py` - Amazon Moisture, **Î²=14.6**
- `urban_heat_canopy_fit.py` - **Î²=16.3 - HÃ–CHSTER WERT!** ğŸ”¥
- `planetary_tipping_elements_fit.py` - AMOC, GrÃ¶nland, etc.
- `outlier_beta_review.py` - Instrumentation-Flag Ledger (Î”AIC-Gegencheck)

**Ergebnisse:** Klima-Tipping-Points haben EXTREME Î²-Werte (Outliers!) + Ledger prÃ¼ft Instrumentations-Bias.

---

### ğŸ”— Cross-Domain (6 Skripte)
**Highlights:**
- `coupled_field_threshold_fit.py` - Gekoppelte Felder
- `membrane_robin_semantic_fit.py` - Semantic Resonance
- `meta_threshold_resonance_fit.py` - Adaptive Î˜(t), Î²(t)
- `adaptive_theta_typology.py` - Typologisierung

**Ergebnisse:** Cross-Domain Resonanzen zeigen universelle Muster

---

## ğŸ“ˆ Key Metrics aus Cohort-Summary

**Gesamtstatistik Ã¼ber alle Fits:**
- **Median RÂ²:** ~0.9981 ğŸ¯
- **Median Î”AIC:** ~65.1 (gegen linear/power-law nulls)
- **Î²-Spektrum:** 2.5 bis 16.3 (nicht fix!)
- **Threshold-Crossings:** Dokumentiert fÃ¼r jede Membran

**Das beweist:** Logistische Modelle schlagen Null-Modelle KONSISTENT!

---

## ğŸ” Wie finde ich ein Skript?

### Methode 1: Nach Domain suchen
```bash
# Alle AI-Fits
ls analysis/*llm*.py

# Alle Biology-Fits
ls analysis/*lenski*.py analysis/*synaptic*.py analysis/*honeybee*.py

# Alle Socio-Ecology-Fits
ls analysis/*amazon*.py analysis/*urban*.py analysis/*planetary*.py
```

### Methode 2: Nach Funktion suchen
```bash
# Batch-Processing
ls analysis/*batch*.py analysis/*cohort*.py analysis/*bridge*.py

# Meta-Analysen
ls analysis/*meta*.py analysis/*universality*.py

# Utilities
ls analysis/*correction*.py analysis/*guard*.py analysis/*diagnostics*.py
```

### Methode 3: Programmatisch (Python)
```python
import json

# Lade Index
with open('analysis/analysis_index.json', 'r') as f:
    index = json.load(f)

# Finde alle high-relevance Skripte
high_rel = [s for s in index['python_scripts'] if s['relevance'] == 'high']

# Finde alle AI-Domain Skripte
ai_scripts = [s for s in index['python_scripts'] if s.get('domain') == 'ai']

# Finde Skripte nach Keyword
beta_scripts = [s for s in index['python_scripts']
                if 'Î²-extraction' in s['keywords']]
```

---

## ğŸ¯ Wichtige Workflows

### Workflow 1: Neuen Domain-Fit erstellen
1. Schreibe `{domain}_{system}_fit.py`
2. Importiere aus `models/` (z.B. `logistic_threshold.py`)
3. Lade Daten aus `data/{domain}/`
4. Fitte Ïƒ(Î²(R-Î˜))
5. Vergleiche mit Null-Modellen (linear, power-law)
6. Exportiere nach `results/{domain}_{system}_fit.json`
7. Update `resonance_cohort_summary.py`

### Workflow 2: Batch-Run ausfÃ¼hren
```bash
# 1. Konfiguriere in batch_configs/
vi batch_configs/my_run.yaml

# 2. FÃ¼hre Batch-Runner aus
python analysis/resonance_batch_runner.py --config batch_configs/my_run.yaml

# 3. Check Results
cat results/my_run_result.json
```

### Workflow 3: Meta-Regression updaten
```bash
# FÃ¼r UTAC v1.2 kritisch!
python analysis/beta_drivers_meta_regression.py

# Check RÂ²
# Ziel: RÂ² > 0.7 (aktuell: 0.33)
```

---

## ğŸš€ FÃ¼r AI-Agenten

### Quick Access Patterns

```python
import json

with open('analysis/analysis_index.json', 'r') as f:
    idx = json.load(f)

# Get critical scripts for UTAC v1.2
critical = idx['quicklinks']['critical_for_utac']

# Get high-impact fits
high_impact = idx['quicklinks']['high_impact_fits']

# Get all domain scripts
domains = idx['domains']

# Get results directory info
results_dir = idx['subdirectories']['results']
```

### Batch Processing Interface

```python
# Load batch config
with open('analysis/batch_configs/resonance_runs.json') as f:
    config = json.load(f)

# Run batch
from analysis import resonance_batch_runner
resonance_batch_runner.run(config)

# Get cohort summary
from analysis import resonance_cohort_summary
summary = resonance_cohort_summary.generate()

# Validate canonical Î² guard
from analysis import universal_beta_extractor
universal_beta_extractor.main(["--mode", "validate", "--output", "out/master_beta_report.json"])
```

---

## ğŸ”¥ Die Outliers (WICHTIG fÃ¼r v1.2!)

**Î²-Werte Ã¼ber 14:**
1. **urban_heat_canopy** - Î²=16.3 ğŸ”¥ğŸ”¥ğŸ”¥ (EXTREM!)
2. **seismic_rupture_threshold** - Î²=16.29
3. **amazon_resilience** - Î²=14.6

**Warum sind die so hoch?**
- Nichtlineare Materialeigenschaften? (Urban Heat)
- Extreme Kopplung? (Seismik)
- Unentdeckte RÃ¼ckkopplungen? (Amazon)

**Neuer Guard:** `outlier_beta_review.py` â†’ `analysis/results/outlier_beta_review.json`
- Amazon: `genuine_regime_split`
- Urban Heat: `requires_follow_up` (InstrumentationsprÃ¼fung weiterfÃ¼hren!)

**â†’ Muss in UTAC v1.2 Outlier-Analyse untersucht werden!**

---

## ğŸ“š Referenzen

**Lies auch:**
- `README.md` - RepoPlan 2.0 Mandate
- `AGENTS.md` - Resonance Protocols
- `../seed/seed_index.md` - Seed-Verzeichnis Navigation
- `../data/data_index.md` - Data-Verzeichnis (kommt noch!)
- `../models/models_index.md` - Models-Verzeichnis (kommt noch!)

---

## ğŸ¨ Tri-Layer Cadence

**Aus dem RepoPlan 2.0 Mandate:**

> **Formal:** Derive parameter posteriors and impedance sensitivities Î¶(R)
> **Empirisch:** Showcase cross-domain evidence with resonance steepness diagnostics
> **Metaphorisch:** Narrate how data traces the waxing of resonance, letting the logistic curve function as a dawn chorus across domains

**Das heiÃŸt:** Jeder Fit muss 3 Perspektiven haben:
1. **Mathematisch** - Parameter, CIs, Î”AIC
2. **Empirisch** - Daten, DomÃ¤ne, Kontext
3. **Narrativ** - Was bedeutet der Threshold?

---

## ğŸ’¡ Tips & Best Practices

### FÃ¼r Menschen:
1. **Start mit README.md** - RepoPlan 2.0 Mandate lesen
2. **Check Cohort-Summary** - Gesamtstatistik verstehen
3. **Folge Domain-Highlights** - Deine DomÃ¤ne finden
4. **Nutze results/** - Alle Fit-Ergebnisse dort

### FÃ¼r AI-Agenten:
1. **Lade analysis_index.json** - Strukturierter Zugriff
2. **Nutze Quicklinks** - Vordefinierte Einstiegspunkte
3. **Check relevance** - Priorisiere high-relevance Skripte
4. **Respektiere Tri-Layer** - Formal, Empirisch, Metaphorisch

### FÃ¼r das Projekt:
1. **Halte Index aktuell** - Neue Skripte hinzufÃ¼gen!
2. **Exportiere nach results/** - Konsistentes Format
3. **Update Cohort-Summary** - Nach jedem neuen Fit
4. **Dokumentiere Outliers** - Extreme Î²-Werte markieren

---

## ğŸŒŠ Die Essenz

> **"Jeder Fit ist ein Beweis. Jeder Î”AIC ist eine Widerlegung der Null-Hypothese. Zusammen formen sie das Î²-Spektrum - den Kern von UTAC."**

> **"Von Wei's PaLM (Î²=3.47) bis Urban Heat (Î²=16.3) - das Spektrum ist REAL."**

> **"Die Meta-Regression (RÂ²=0.33) ist nicht das Ende - sie ist der Anfang von UTAC v1.2."**

---

**Viel Erfolg beim Analysieren! ğŸ“Šâœ¨**

---

*Erstellt im Geiste der Resonance Bay, wo logistische Kurven wie Dawn Choruses Ã¼ber DomÃ¤nen hinweg erklingen.* ğŸŒ…
